{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b74e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sentence_transformers.models import Transformer, Pooling\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2b49b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e61823899f7406091ba639a06888211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/687 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4226732270d941758d24ea73fdcb4c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee6448058c444d393df22b87f953770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0080d21bad3746ea824a0ab2de8cd145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/444 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c29dbb02bd464588cf08dcd3277fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1dabaf04914c37b7905e47b6109caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc1758abb5624b59898beb86fe8f6d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 'bge_m3_finetuned_local'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 1. 원래 모델과 토크나이저 로드\n",
    "# model = torch.load(\"best_model_full.pt\", map_location=torch.device('cpu'))  # 로컬 .pt 파일\n",
    "model = AutoModel.from_pretrained(\"BAAI/bge-m3\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-m3\")\n",
    "\n",
    "# 2. 모델을 SentenceTransformer로 래핑\n",
    "# modules는 Transformer와 Pooling 레이어로 구성\n",
    "transformer = Transformer(model_name_or_path=\"BAAI/bge-m3\")\n",
    "transformer.auto_model = model  # 로드한 모델로 교체\n",
    "pooling = Pooling(model.config.hidden_size, pooling_mode=\"mean\")  # bge-m3은 mean pooling 사용\n",
    "\n",
    "st_model = SentenceTransformer(modules=[transformer, pooling])\n",
    "\n",
    "# 3. 변환된 모델 저장\n",
    "st_model.save(\"bge_m3_finetuned_local\")\n",
    "print(\"모델이 'bge_m3_finetuned_local'에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62d0b448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'bge_m3_finetuned_local/'에서 모델을 성공적으로 불러왔습니다.\n"
     ]
    }
   ],
   "source": [
    "local_model_path = \"bge_m3_finetuned_local/\"\n",
    "\n",
    "try:\n",
    "    # AutoModel을 사용하여 로컬 모델을 불러옵니다.\n",
    "    # model = AutoModel.from_pretrained(local_model_path)\n",
    "    # print(f\"'{local_model_path}'에서 모델을 성공적으로 불러왔습니다.\")\n",
    "\n",
    "    transformer = Transformer(model_name_or_path=local_model_path)\n",
    "    transformer.auto_model = model  # 로드한 모델로 교체\n",
    "    pooling = Pooling(model.config.hidden_size, pooling_mode=\"mean\")  # bge-m3은 mean pooling 사용\n",
    "\n",
    "    st_model = SentenceTransformer(modules=[transformer, pooling])\n",
    "    \n",
    "    print(f\"'{local_model_path}'에서 모델을 성공적으로 불러왔습니다.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"모델을 불러오는 중 오류가 발생했습니다: {e}\")\n",
    "    print(\"경로가 정확한지, 모델 파일이 손상되지 않았는지 확인해주세요.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08c84b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'bge_m3_finetuned_local/'에서 모델을 성공적으로 불러왔습니다.\n",
      "데이터 디렉토리: dataset/\n",
      "로드할 파일: dataset/code-switch.json\n",
      "로드된 데이터 일부 (첫 번째 항목): {'EtoK': 'Could you explain how 양자 컴퓨팅 and 양자 얽힘 make it possible to solve certain problems faster than classical methods?', 'KtoE': '고전적 방식보다 더 효율적인 quantum computing과 quantum entanglement의 핵심 원리는 무엇인가요?', 'English': 'Could you explain how quantum computing and quantum entanglement make it possible to solve certain problems faster than classical methods?', 'Korean': '양자 컴퓨팅과 양자 얽힘이 일부 문제를 고전적 방법보다 더 빠르게 해결하도록 만드는 핵심 원리는 무엇인가요?'}\n",
      "로드할 파일: dataset/code-switch1.json\n",
      "로드된 데이터 일부 (첫 번째 항목): {'topic': 'science/technology', 'type': 'fact', 'complexity': 'simple', 'contents': 'brief', 'EtoK': 'The 원자 is the basic unit of matter.', 'KtoE': '원자는 matter의 기본 단위이다.', 'English': 'The atom is the basic unit of matter.', 'Korean': '원자는 물질의 기본 단위이다.'}\n",
      "로드할 파일: dataset/code-switch2.json\n",
      "로드된 데이터 일부 (첫 번째 항목): {'topic': 'science/technology', 'type': 'fact', 'complexity': 'simple', 'contents': 'brief', 'EtoK': 'The 블랙홀 is a space region with extreme gravity.', 'KtoE': '블랙홀은 극심한 gravity를 가진 우주 영역이다.', 'English': 'The black hole is a space region with extreme gravity.', 'Korean': '블랙홀은 극심한 중력을 가진 우주 영역이다.'}\n",
      "총 로드된 데이터 항목 수: 269\n",
      "긍정 및 부정 샘플 생성 시작...\n",
      "생성된 학습 예시 0: {'text': ['Could you explain how quantum computing and quantum entanglement make it possible to solve certain problems faster than classical methods?', '여러 요인이 작용하지만, 인플레이션은 소비자 지출에 미치는 영향으로 심각한 경제 문제로 남는다.'], 'label': 0}\n",
      "생성된 학습 예시 1: {'text': ['Can you describe how Generative Adversarial Networks use both a generator and a discriminator to produce realistic images?', '한국의 김치는 유네스코 무형문화유산으로 등재되었습니다. 가장 흔한 김치 종류는 무엇인가요?'], 'label': 0}\n",
      "생성된 학습 예시 2: {'text': ['Could you explain how self-healing materials with embedded catalysts can automatically repair cracks?', '의견이 다르더라도, 1989년 베를린 장벽의 붕괴가 자유를 상징하며 문화 지형을 변화시켰다고 볼 수 있나요?'], 'label': 0}\n",
      "생성된 학습 예시 3: {'text': ['How does a brain-computer interface decode neural signals and translate them into machine commands?', '행동 경제학에서 투자 결정에 영향을 주는 인지적 편향은 무엇인가요?'], 'label': 0}\n",
      "생성된 학습 예시 4: {'text': ['In what ways does mixed reality leverage computer vision to overlay digital objects onto the physical world?', '농구는 코트에서 진행되며 빠른 속도와 높은 득점으로 유명하다.'], 'label': 0}\n",
      "총 생성된 학습 예시 수: 1613\n",
      "Hugging Face Dataset 생성 완료.\n",
      "Dataset 예시 (첫 번째 항목): {'text': ['Could you explain how quantum computing and quantum entanglement make it possible to solve certain problems faster than classical methods?', '양자 컴퓨팅과 양자 얽힘이 일부 문제를 고전적 방법보다 더 빠르게 해결하도록 만드는 핵심 원리는 무엇인가요?'], 'labels': 1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4afc591b0e6d4f228a1177b6db9aa5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1613 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰화 함수 호출됨.\n",
      "토큰화 결과 (일부): [[0, 191147, 398, 73342, 3642, 110436, 242122, 136, 110436, 22, 14525, 19929, 3249, 442, 7722, 47, 86869, 24233, 44402, 4271, 56, 3501, 54704, 289, 150624, 32, 2, 2, 16837, 2268, 6, 93721, 201692, 33994, 1291, 16837, 2268, 6, 249806, 238153, 469, 55245, 138153, 6086, 3776, 3761, 29152, 21491, 6116, 147660, 63054, 109690, 107900, 119199, 10380, 40771, 227539, 5144, 32, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 191147, 398, 73342, 3642, 110436, 242122, 136, 110436, 22, 14525, 19929, 3249, 442, 7722, 47, 86869, 24233, 44402, 4271, 56, 3501, 54704, 289, 150624, 32, 2, 2, 4865, 186768, 19732, 14602, 25134, 26320, 25, 7, 43454, 202, 10013, 159202, 67, 32, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "토큰화 함수 호출됨.\n",
      "토큰화 결과 (일부): [[0, 4171, 398, 39563, 450, 7270, 4, 10670, 157272, 100, 6863, 4927, 4, 83, 70, 10323, 111, 9942, 32, 2, 2, 120059, 1083, 166142, 14971, 107707, 9942, 367, 49259, 140376, 24921, 103130, 5144, 32, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 4171, 398, 39563, 450, 7270, 4, 10670, 157272, 100, 6863, 4927, 4, 83, 70, 10323, 111, 9942, 32, 2, 2, 7159, 3575, 2268, 9450, 51415, 107707, 68204, 23928, 20584, 4, 10380, 48894, 91681, 697, 190521, 1083, 115676, 16725, 2905, 18692, 112116, 3761, 21806, 195925, 5, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "데이터셋 토큰화 완료.\n",
      "TrainingArguments 설정 완료.\n",
      "TrainingArguments: TrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=None,\n",
      "eval_strategy=no,\n",
      "eval_use_gather_object=False,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=None,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=['labels'],\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./logs_transformers,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=./bge-m3-finetuned-transformers,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./bge-m3-finetuned-transformers,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=epoch,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tp_size=0,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      ")\n",
      "Trainer 객체 생성 완료.\n",
      "모델 파인튜닝 시작...\n",
      "compute_loss inputs 키: dict_keys(['labels', 'input_ids', 'attention_mask'])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "입력 형태가 예상과 다릅니다. 데이터셋 생성 및 토큰화 과정을 확인하세요.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 191\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# 모델 파인튜닝 시작\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m모델 파인튜닝 시작...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 191\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m모델 파인튜닝 완료!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# 4. 결과 확인\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# (선택 사항) 파인튜닝된 모델 저장\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2560\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2553\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2554\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2556\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2557\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2558\u001b[0m )\n\u001b[1;32m   2559\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2560\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2563\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2564\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2565\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2566\u001b[0m ):\n\u001b[1;32m   2567\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2568\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3736\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3733\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3735\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3736\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3738\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3740\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3741\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3742\u001b[0m ):\n",
      "Cell \u001b[0;32mIn[9], line 153\u001b[0m, in \u001b[0;36mContrastiveTrainer.compute_loss\u001b[0;34m(self, model, inputs, num_items_in_batch, return_outputs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     attention_mask_2 \u001b[38;5;241m=\u001b[39m attention_mask[:, \u001b[38;5;241m1\u001b[39m, :]\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# 두 문장이 합쳐져서 토큰화된 경우, 적절한 분리 로직이 필요합니다.\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# 이 예시에서는 간단하게 처리하거나, 데이터셋 생성 방식을 수정하는 것을 고려합니다.\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m입력 형태가 예상과 다릅니다. 데이터셋 생성 및 토큰화 과정을 확인하세요.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# 두 개의 텍스트를 각각 인코딩\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: 입력 형태가 예상과 다릅니다. 데이터셋 생성 및 토큰화 과정을 확인하세요."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, TrainingArguments, Trainer\n",
    "from datasets import Dataset  # Hugging Face Datasets 라이브러리\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader  # 직접 데이터 로딩 시 사용\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "# 1. 모델 로드\n",
    "local_model_path = \"bge_m3_finetuned_local/\"\n",
    "\n",
    "try:\n",
    "    # AutoModel을 사용하여 로컬 모델을 불러옵니다.\n",
    "    model = AutoModel.from_pretrained(local_model_path)\n",
    "    print(f\"'{local_model_path}'에서 모델을 성공적으로 불러왔습니다.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"모델을 불러오는 중 오류가 발생했습니다: {e}\")\n",
    "    print(\"경로가 정확한지, 모델 파일이 손상되지 않았는지 확인해주세요.\")\n",
    "    exit() # 모델 로드 실패 시 프로그램 종료\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path) # 토크나이저도 로컬에서 로드\n",
    "\n",
    "# 2. 데이터 로드 및 전처리\n",
    "\n",
    "# JSON 파일들이 있는 디렉토리 또는 파일 경로 리스트\n",
    "data_dir = \"dataset/\"  # 실제 JSON 파일들이 있는 디렉토리 경로로 변경\n",
    "\n",
    "# 데이터 로드 함수 (여러 JSON 파일 처리)\n",
    "def load_multiple_data(data_path):\n",
    "    combined_data = []\n",
    "    if isinstance(data_path, str):\n",
    "        print(f\"데이터 디렉토리: {data_path}\")\n",
    "        for filename in os.listdir(data_path):\n",
    "            if filename.endswith(\".json\"):\n",
    "                file_path = os.path.join(data_path, filename)\n",
    "                print(f\"로드할 파일: {file_path}\")\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                    print(f\"로드된 데이터 일부 (첫 번째 항목): {data[0] if data else None}\")\n",
    "                    combined_data.extend(data)\n",
    "    elif isinstance(data_path, list):\n",
    "        print(f\"데이터 파일 리스트: {data_path}\")\n",
    "        for file_path in data_path:\n",
    "            print(f\"로드할 파일: {file_path}\")\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                print(f\"로드된 데이터 일부 (첫 번째 항목): {data[0] if data else None}\")\n",
    "                combined_data.extend(data)\n",
    "    print(f\"총 로드된 데이터 항목 수: {len(combined_data)}\")\n",
    "    return combined_data\n",
    "\n",
    "# JSON 파일들을 로드합니다.\n",
    "if isinstance(data_dir, str):\n",
    "    data = load_multiple_data(data_dir)\n",
    "else:\n",
    "    data = load_multiple_data(data_dir)\n",
    "\n",
    "train_examples = []\n",
    "print(\"긍정 및 부정 샘플 생성 시작...\")\n",
    "for i, item in enumerate(data):\n",
    "    english = item.get(\"English\")\n",
    "    korean = item.get(\"Korean\")\n",
    "    etoK = item.get(\"EtoK\")\n",
    "    KtoE = item.get(\"KtoE\")\n",
    "\n",
    "    if english and korean:\n",
    "        train_examples.append({\"text\": [english, korean], \"label\": 1}) # 긍정 (같은 의미)\n",
    "        # 부정 샘플 (다른 의미의 문장과 페어링) - 간단한 예시\n",
    "        negative_item = random.choice(data)\n",
    "        negative_english = negative_item.get(\"English\")\n",
    "        if negative_english and negative_english != english:\n",
    "            train_examples.append({\"text\": [english, negative_english], \"label\": 0})\n",
    "\n",
    "    if korean and etoK:\n",
    "        train_examples.append({\"text\": [korean, etoK], \"label\": 1}) # 긍정\n",
    "        negative_item = random.choice(data)\n",
    "        negative_english = negative_item.get(\"English\")\n",
    "        if negative_english and negative_english != korean:\n",
    "            train_examples.append({\"text\": [korean, negative_english], \"label\": 0})\n",
    "\n",
    "    if english and KtoE:\n",
    "        train_examples.append({\"text\": [english, KtoE], \"label\": 1}) # 긍정\n",
    "        negative_item = random.choice(data)\n",
    "        negative_korean = negative_item.get(\"Korean\")\n",
    "        if negative_korean and negative_korean != english:\n",
    "            train_examples.append({\"text\": [english, negative_korean], \"label\": 0})\n",
    "\n",
    "    if i < 5: # 처음 몇 개 샘플만 출력하여 확인\n",
    "        print(f\"생성된 학습 예시 {i}: {train_examples[-1] if train_examples else None}\")\n",
    "\n",
    "print(f\"총 생성된 학습 예시 수: {len(train_examples)}\")\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"text\": [item[\"text\"] for item in train_examples],\n",
    "    \"labels\": [item[\"label\"] for item in train_examples]\n",
    "})\n",
    "print(\"Hugging Face Dataset 생성 완료.\")\n",
    "print(f\"Dataset 예시 (첫 번째 항목): {train_dataset[0] if train_dataset else None}\")\n",
    "\n",
    "# 토큰화 함수\n",
    "def tokenize_function(examples):\n",
    "    print(\"토큰화 함수 호출됨.\")\n",
    "    result = tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "    print(f\"토큰화 결과 (일부): {result['input_ids'][:2] if result['input_ids'] else None}\")\n",
    "    return result\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "print(\"데이터셋 토큰화 완료.\")\n",
    "# print(f\"토큰화된 Dataset 예시 (첫 번째 항목): {tokenized_train_dataset[0] if tokenized_train_dataset else None}\")\n",
    "\n",
    "# 3. 파인튜닝\n",
    "\n",
    "# 학습 하이퍼파라미터 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bge-m3-finetuned-transformers\",\n",
    "    per_device_train_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    # evaluation_strategy=\"epoch\", # 필요하다면 평가 데이터셋 준비\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs_transformers\",\n",
    "    report_to=\"none\",\n",
    "    label_names=[\"labels\"]\n",
    ")\n",
    "print(\"TrainingArguments 설정 완료.\")\n",
    "print(f\"TrainingArguments: {training_args}\")\n",
    "\n",
    "# 모델을 위한 사용자 정의 Trainer (손실 함수 변경)\n",
    "class ContrastiveTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, num_items_in_batch=None, return_outputs=False):\n",
    "        print(f\"compute_loss inputs 키: {inputs.keys()}\")\n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        attention_mask = inputs[\"attention_mask\"]\n",
    "        labels = inputs[\"labels\"]\n",
    "        batch_size = input_ids.size(0)\n",
    "\n",
    "        # input_ids와 attention_mask는 (batch_size, seq_length) 형태일 것입니다.\n",
    "        # 이진 분류를 위해 두 문장을 하나로 합쳐서 토큰화했을 가능성을 고려하여 처리합니다.\n",
    "        # 또는 데이터셋 생성 시 이미 [text1, text2] 형태로 되어 있다면 아래와 같이 분리할 수 있습니다.\n",
    "        # (batch_size, 2, seq_length) 형태라고 가정하고 분리합니다.\n",
    "        if len(input_ids.shape) > 2 and input_ids.shape[1] == 2:\n",
    "            input_ids_1 = input_ids[:, 0, :]\n",
    "            attention_mask_1 = attention_mask[:, 0, :]\n",
    "            input_ids_2 = input_ids[:, 1, :]\n",
    "            attention_mask_2 = attention_mask[:, 1, :]\n",
    "        else:\n",
    "            # 두 문장이 합쳐져서 토큰화된 경우, 적절한 분리 로직이 필요합니다.\n",
    "            # 이 예시에서는 간단하게 처리하거나, 데이터셋 생성 방식을 수정하는 것을 고려합니다.\n",
    "            raise ValueError(\"입력 형태가 예상과 다릅니다. 데이터셋 생성 및 토큰화 과정을 확인하세요.\")\n",
    "\n",
    "        # 두 개의 텍스트를 각각 인코딩\n",
    "        try:\n",
    "            outputs1 = model(input_ids_1, attention_mask=attention_mask_1)\n",
    "            embeddings1 = outputs1.last_hidden_state.mean(dim=1) # 또는 다른 풀링 방식\n",
    "\n",
    "            outputs2 = model(input_ids_2, attention_mask=attention_mask_2)\n",
    "            embeddings2 = outputs2.last_hidden_state.mean(dim=1) # 또는 다른 풀링 방식\n",
    "\n",
    "            # 코사인 유사도 계산\n",
    "            cos_sim = torch.nn.functional.cosine_similarity(embeddings1, embeddings2)\n",
    "\n",
    "            # 목표: 같은 의미면 유사도 높이기 (label 1), 다른 의미면 유사도 낮추기 (label 0)\n",
    "            # 간단한 이진 분류 손실 함수 (조정 필요)\n",
    "            loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "            logits = cos_sim # 코사인 유사도를 로짓으로 사용 (적절한 스케일링 필요할 수 있음)\n",
    "            loss = loss_fn(logits.unsqueeze(1), labels.float().unsqueeze(1))\n",
    "\n",
    "            print(f\"배치 손실: {loss.item()}\")\n",
    "            return loss\n",
    "        except Exception as e:\n",
    "            print(f\"compute_loss 오류 발생: {e}\")\n",
    "            print(f\"입력 input_ids 형태: {input_ids.shape}\")\n",
    "            print(f\"입력 attention_mask 형태: {attention_mask.shape}\")\n",
    "            print(f\"입력 labels 형태: {labels.shape}\")\n",
    "            raise\n",
    "\n",
    "# Trainer 객체 생성\n",
    "trainer = ContrastiveTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset\n",
    ")\n",
    "print(\"Trainer 객체 생성 완료.\")\n",
    "\n",
    "# 모델 파인튜닝 시작\n",
    "print(\"모델 파인튜닝 시작...\")\n",
    "trainer.train()\n",
    "\n",
    "print(\"모델 파인튜닝 완료!\")\n",
    "\n",
    "# 4. 결과 확인\n",
    "\n",
    "# (선택 사항) 파인튜닝된 모델 저장\n",
    "trainer.save_model(\"./bge-m3-finetuned-transformers-best\")\n",
    "tokenizer.save_pretrained(\"./bge-m3-finetuned-transformers-best\")\n",
    "print(\"최고 성능 모델 및 토크나이저가 './bge-m3-finetuned-transformers-best'에 저장되었습니다.\")\n",
    "\n",
    "# (선택 사항) 추론 또는 임베딩 생성에 파인튜닝된 모델 활용\n",
    "def get_embeddings(texts, model, tokenizer):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.cpu().numpy()\n",
    "\n",
    "if data:\n",
    "    sample_item = data[0]\n",
    "    english_text = sample_item.get(\"English\")\n",
    "    korean_text = sample_item.get(\"Korean\")\n",
    "    etoK_text = sample_item.get(\"EtoK\")\n",
    "\n",
    "    if english_text and korean_text and etoK_text:\n",
    "        finetuned_embeddings_en = get_embeddings([english_text], trainer.model, tokenizer)\n",
    "        finetuned_embeddings_ko = get_embeddings([korean_text], trainer.model, tokenizer)\n",
    "        finetuned_embeddings_ek = get_embeddings([etoK_text], trainer.model, tokenizer)\n",
    "\n",
    "        print(\"\\n--- 파인튜닝 후 임베딩 (예시) ---\")\n",
    "        print(f\"영어 임베딩 (처음 5개): {finetuned_embeddings_en.flatten()[:5]}\")\n",
    "        print(f\"한국어 임베딩 (처음 5개): {finetuned_embeddings_ko.flatten()[:5]}\")\n",
    "        print(f\"EtoK 임베딩 (처음 5개): {finetuned_embeddings_ek.flatten()[:5]}\")\n",
    "\n",
    "# 추가적인 평가를 위해서는 별도의 평가 데이터셋과 metric을 정의해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "061619b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text', 'labels', 'input_ids', 'attention_mask'])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokenized_train_dataset[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtokenized_train_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset[0].keys())\n",
    "print(tokenized_train_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc03ba4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
