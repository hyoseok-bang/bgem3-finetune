import os
import json
import random


class TokenizerHelper:
    """
    A helper class for tokenizing input text examples using a tokenizer.
    This class processes the input text data by applying tokenization,
    truncating sequences to a maximum length, and padding them to ensure
    uniform input size. The tokenized results include input IDs and other
    relevant information.
    """

    def __init__(self, tokenizer):
        """
        Initializes the TokenizerHelper with a tokenizer instance.

        Args:
            tokenizer: A tokenizer instance from the Hugging Face Transformers library.
        """
        self.tokenizer = tokenizer

    def tokenize_function(self, examples):
        """
        Tokenizes input text examples using the initialized tokenizer.

        Args:
            examples (dict): A dictionary containing input text data.
                             The key "text" is expected to hold the text to be tokenized.

        Returns:
            dict: A dictionary containing the tokenized output, including:
                  - 'input_ids': List of token IDs for the input text.
                  - Other fields as generated by the tokenizer.

        Side Effects:
            Prints debug information about the tokenization process, including:
            - A message indicating the function was called.
            - A preview of the tokenization results (up to the first two input IDs).
        """
        print("토큰화 함수 호출됨.")
        result = self.tokenizer(
            examples["text"], truncation=True, padding="max_length", max_length=128
        )
        print(
            f"토큰화 결과 (일부): {result['input_ids'][:2] if result['input_ids'] else None}"
        )
        return result


def load_multiple_data(data_path):
    """Loads and combines data from multiple JSON files.

    Args:
        data_path (str or list): Path to a directory or list of file paths containing JSON files.

    Returns:
        list: A combined list of data from all JSON files.
    """
    combined_data = []
    if isinstance(data_path, str):
        print(f"데이터 디렉토리: {data_path}")
        for filename in os.listdir(data_path):
            if filename.endswith(".json"):
                file_path = os.path.join(data_path, filename)
                print(f"로드할 파일: {file_path}")
                with open(file_path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    print(
                        f"로드된 데이터 일부 (첫 번째 항목): {data[0] if data else None}"
                    )
                    combined_data.extend(data)
    elif isinstance(data_path, list):
        print(f"데이터 파일 리스트: {data_path}")
        for file_path in data_path:
            print(f"로드할 파일: {file_path}")
            with open(file_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                print(f"로드된 데이터 일부 (첫 번째 항목): {data[0] if data else None}")
                combined_data.extend(data)
    print(f"총 로드된 데이터 항목 수: {len(combined_data)}")
    return combined_data


def make_train_dataset(data):
    """
    Generates a training dataset with positive and negative examples from the given data.
    Args:
        data (list of dict): A list of dictionaries where each dictionary contains the following keys:
            - "English" (str): An English sentence.
            - "Korean" (str): A Korean sentence.
            - "EtoK" (str): A Korean translation of the English sentence.
            - "KtoE" (str): An English translation of the Korean sentence.
    Returns:
        list of dict: A list of training examples, where each example is a dictionary with:
            - "text" (list of str): A pair of sentences (e.g., [sentence1, sentence2]).
            - "label" (int): 1 for positive examples (same meaning), 0 for negative examples (different meaning).
    Behavior:
        - For each item in the input data, the function generates positive examples by pairing sentences
          with their translations and assigns a label of 1.
        - Negative examples are generated by pairing sentences with randomly chosen sentences from the dataset
          that have different meanings, and these are assigned a label of 0.
        - The function prints the first few generated examples for verification and logs the total number
          of generated examples.
    Note:
        - The function assumes that the input data is well-formed and contains the expected keys.
        - Random negative sampling may result in duplicate or less diverse negative examples depending on the dataset size.
    """

    train_examples = []
    print("긍정 및 부정 샘플 생성 시작...")
    for i, item in enumerate(data):
        english = item.get("English")
        korean = item.get("Korean")
        etoK = item.get("EtoK")
        KtoE = item.get("KtoE")

        if english and korean:
            train_examples.append(
                {"text": [english, korean], "label": 1}
            )  # 긍정 (같은 의미)
            # 부정 샘플 (다른 의미의 문장과 페어링) - 간단한 예시
            negative_item = random.choice(data)
            negative_english = negative_item.get("English")
            if negative_english and negative_english != english:
                train_examples.append({"text": [english, negative_english], "label": 0})

        if korean and etoK:
            train_examples.append({"text": [korean, etoK], "label": 1})  # 긍정
            negative_item = random.choice(data)
            negative_english = negative_item.get("English")
            if negative_english and negative_english != korean:
                train_examples.append({"text": [korean, negative_english], "label": 0})

        if english and KtoE:
            train_examples.append({"text": [english, KtoE], "label": 1})  # 긍정
            negative_item = random.choice(data)
            negative_korean = negative_item.get("Korean")
            if negative_korean and negative_korean != english:
                train_examples.append({"text": [english, negative_korean], "label": 0})

        if i < 5:  # 처음 몇 개 샘플만 출력하여 확인
            print(
                f"생성된 학습 예시 {i}: {train_examples[-1] if train_examples else None}"
            )

    print(f"총 생성된 학습 예시 수: {len(train_examples)}")

    return train_examples
